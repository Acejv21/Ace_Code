1.We used the pop function to split the labels for the training set. The name of the data set is “species” 

 2.) 
 the five types of estimates are:
•	tf.estimator.DNNClassifier for deep models that perform multi-class classification.
•	tf.estimator.DNNLinearCombinedClassifier for wide & deep models.
•	tf.estimator.LinearClassifier for classifiers based on linear models.
•	The config argument can be passed tf.estimator.RunConfig object containing information about the execution environment.  
•	 Estimator. tf.estimator.WarmStartSettings.

3.)
The purpose of the input function is to create supply data for training, evaluating, and prediction A feature column is an object describing how the model should use raw input data from the features dictionary. When you build an Estimator model, you pass it a list of feature columns that describes each of the features you want the model to use. The tf.feature_column module provides many options for representing data to the model.

4.) 
The command classifier trains the models by calling the estimators train method. We rap up the input_fn call in a lambda, to capture the arguments, as well as provide an input function that takes no arguments. We are applying the lambda nested function to the training set of data.

5.) 

the linearClassifier ran and retuned an accuracy of .933. which was the best out of all the classifiers I attempted. This makes sense because this classifier is meant for multi classification. The next DNNClasifier .867 accuracy and finaly the DNNLinearCombinedClassifier was last at .773. 

B.  
the images below  have a similar graphs for age because they both shared x axis values that produced a similar out come for that veriable in the data. 

A catagorical column is a column that takes all the variables amd puts them in to a list. a Densfeature is a clulmn that colaberates with the categorical column, wich ocupies the collumns woth binary code such as 0 = False or 1 = True. This layer can be called multiple times with different features/ transforming the object into a indicator column. this is use full for its another way to work the model to get a better understanding of the data being analyzed.  

The featurcolumns wre the LinearClassifier: sex,n_siblings_spouses, parch, class, deck, embark town, alone, age, and fare.  
Accuracy was 0.77, suggests the model is getting better but it is has not achieved a desirable accuracy. 

![Foundation_ kernal](https://github.com/Acejv21/Ace_Code/blob/master/Foundation_%20kernal.png?raw=true)
![Pair_for_B](https://github.com/Acejv21/Ace_Code/blob/master/Pair_for_B.png?raw=true)

